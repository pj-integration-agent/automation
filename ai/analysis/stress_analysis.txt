Relatório Técnico – Análise de Stress‑Test (JTL)

Resumo do cenário de teste  
O teste foi conduzido contra a API pública “https://pokeapi.co/api/v2/pokemon/ditto” utilizando 2 threads de execução, com 20 requisições do tipo GET. Todas as requisições foram realizadas em um intervalo de 9 000 ms (9 s), resultando em 20 chamadas bem-sucedidas (código HTTP 200).

Volume total de requisições  
Total de solicitações registradas: 20.

Throughput estimado  
Throughput = total de requisições / duração do teste = 20 / 9 s ≈ 2,22 requisições por segundo. Esse valor reflete a taxa de produção das requisições no ambiente de teste.

Latência (p50, p90, p95, p99)  
Os valores de latência (coluna “Latency”) foram os seguintes, em ordem crescente: 39 ms, 41 ms, 41 ms, 42 ms, 42 ms, 43 ms, 43 ms, 43 ms, 44 ms, 44 ms, 45 ms, 45 ms, 45 ms, 46 ms, 48 ms, 48 ms, 48 ms, 49 ms, 357 ms, 761 ms.  
Com base nesses dados:  
- p50 (mediana) ≈ 44,5 ms  
- p90 ≈ 49 ms  
- p95 ≈ 357 ms  
- p99 ≈ 761 ms  

Taxa de erros  
Nenhum erro foi registrado; taxa de falhas = 0 %. Todos os 20 requests retornaram HTTP 200.

Principais gargalos identificados  
1. Latências atípicas de 357 ms e 761 ms, que elevam significativamente o p95 e p99, indicando possíveis gargalos de rede ou de processamento da API externa.  
2. O throughput baixo (≈ 2,2 req/s) sugere que a configuração de threads ou o limite de conexão não foram adequados ao objetivo de carga.  
3. Falta de variabilidade nas métricas de latência entre as primeiras duas requisições (conexões ativas) e as demais (conexões fechadas), indicando que a manutenção de conexão (keep‑alive) pode estar contribuindo para a discrepância.

Impacto potencial em ambiente de produção  
Mesmo que a taxa de erro seja nula, os p95 e p99 elevados implicam em experiências de usuário degradadas quando a aplicação dependerá de respostas da API em intervalos críticos. Se o tráfego real atingir centenas ou milhares de requisições por segundo, esses picos de latência podem se multiplicar, resultando em tempos de espera excessivos, timeouts em downstream services e aumento de custos de rede e infra‑estrutura.

Recomendações técnicas claras e acionáveis  
1. **Otimização de conexão** – habilitar e configurar corretamente keep‑alive na camada HTTP/1.1 ou HTTP/2. Isso reduzirá o overhead de estabelecimento de conexão e poderá mitigar latências elevadas em requisições subsequentes.  
2. **Pool de conexões** – configurar um pool de conexões no cliente HTTP (ex.: Apache HttpClient, OkHttp, etc.) para reutilizar sockets e reduzir latência de conexão inicial.  
3. **Balanceamento de carga e redundância** – se possível, distribuir as chamadas entre múltiplos nós da API ou usar um serviço de proxy que balanceie a carga, diminuindo a probabilidade de gargalos concentrados.  
4. **Cache de respostas** – a API retorna dados estáticos sobre o Pokémon “ditto”; implementar caching no lado cliente ou em um proxy reverso (ex.: Varnish, CloudFront) pode eliminar chamadas repetidas e reduzir a latência observada.  
5. **Aumentar o número de threads** – para simular cenários de produção, elevar o número de usuários virtuais (threads) e manter o mesmo número de requisições por usuário. Isso permitirá observar o comportamento de throughput em condições de carga mais realista.  
6. **Monitoramento de métricas** – integrar ferramentas de observabilidade (Prometheus, Grafana, New Relic, etc.) para acompanhar em tempo real latência, throughput e taxa de erros, permitindo detecção precoce de degradação.  
7. **Testes de carga adicionais** – repetir o teste com cargas progressivas (50, 100, 200 requisições simultâneas) para mapear o ponto de saturação e validar a eficácia das otimizações implementadas.  
8. **Análise de logs da API** – se possível, acessar logs internos da API (ou solicitar métricas ao provedor) para identificar se os picos de latência são originados no endpoint ou em camadas externas (DNS, firewall, CDN).  

Implementação dessas ações reduzirá as latências atípicas, aumentará o throughput e garantirá maior confiabilidade e desempenho em produção.