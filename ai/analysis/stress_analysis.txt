Relatório Técnico – Teste de Stress JMeter

Resumo do Cenário de Teste  
O teste foi executado com uma única thread que enviou 20 requisições GET ao endpoint https://pokeapi.co/api/v2/pokemon/ditto, simulando um cenário de carga leve em que o objetivo era avaliar a estabilidade e latência de respostas. Todas as requisições foram realizadas em sequência, sem paralelismo, e os resultados foram coletados num arquivo JTL resumido contendo tempo de execução, latência e dados de conexão.

Volume Total de Requisições  
Foram registradas 20 requisições HTTP durante o período de teste. O volume total de dados retornados somou aproximadamente 523.000 bytes, enquanto 2.660 bytes foram enviados.

Throughput Estimado  
O intervalo entre o primeiro e o último registro foi de 9.422 milissegundos (9,422 segundos). Assim, o throughput médio foi de 20 / 9,422 ≈ 2,12 requisições por segundo (RPS). Esse valor representa a taxa média de entrega de respostas na configuração de teste atual.

Latência  
Os valores de latência (ms) registrados foram: 334, 33, 32, 20, 31, 29, 28, 24, 28, 47, 23, 22, 27, 21, 23, 18, 25, 24, 26, 23.  
- p50 (mediana): 24 ms  
- p90: 33 ms  
- p95: 334 ms  
- p99: 334 ms  

O pico de latência de 334 ms ocorre em apenas uma requisição e inflaciona os percentis superiores. A maioria das respostas permanece abaixo de 35 ms, indicando boa performance sob carga mínima.

Taxa de Erros  
Todas as 20 requisições retornaram código 200 e foram marcadas como success=true. Portanto, a taxa de erros foi 0 %. Não há falhas de rede ou de aplicação detectadas nesse conjunto de dados.

Principais Gargalos Identificados  
1. Latência de conexão excepcional (Connect = 318 ms na primeira requisição). O tempo de estabelecimento de conexão é significativamente maior que o restante dos valores, sugerindo problemas de TCP handshake ou de resolução de DNS.  
2. Outlier de latência total de 334 ms que eleva os percentis p95 e p99. Esse ponto pode indicar um gargalo no servidor ou no caminho de rede.  
3. A configuração atual usa apenas uma thread; embora isso não gere sobrecarga, ele limita a taxa de requisições e não reflete um cenário de alto tráfego.

Impacto Potencial em Ambiente de Produção  
Em produção, onde a carga pode ser dezenas ou centenas de vezes maior, a conexão lenta pode se tornar um fator crítico. Se o tempo de handshake for recorrente, a aplicação pode enfrentar limites de throughput e, em picos de tráfego, pode ocorrer time‑out ou queda de sessão. Além disso, a presença de latências elevadas pode degradar a experiência do usuário final e aumentar a taxa de rejeição de clientes.

Recomendações Técnicas e Acionáveis  
- Ativar o recurso Keep‑Alive no sampler HTTP para reutilizar conexões TCP, reduzindo o custo de handshake.  
- Configurar JMeter para usar HTTPClient4 com pool de conexões, definindo “Use concurrent pool” e ajustando o tamanho do pool para o número esperado de conexões simultâneas.  
- Verificar a resolução de DNS local; se o domínio for resolvido via servidor DNS remoto, considerar um cache local ou resolver antes de iniciar o teste.  
- Analisar os logs do servidor para a requisição com 334 ms; verificar se há gargalos de processamento interno ou bloqueios de banco de dados.  
- Implementar métricas de monitoramento em tempo real (CPU, memória, I/O de rede) para correlacionar latências altas com possíveis saturações de recursos.  
- Repetir o teste com múltiplas threads (ex.: 10, 20, 50) para avaliar a escalabilidade e identificar limites de throughput.  
- Se o serviço for crítico, considerar a adoção de CDN ou cache de respostas estáticas para reduzir a carga nas instâncias de back‑end.

Essas ações permitirão reduzir a latência de conexão, aumentar o throughput e garantir que a aplicação suporte picos de tráfego sem comprometer a qualidade do serviço.