Resumo do cenário de teste  
O teste foi executado com o Apache JMeter enviando requisições GET para o endpoint https://pokeapi.co/api/v2/pokemon/ditto. O script foi configurado com 20 threads, cada uma efetuando uma única requisição, resultando em um conjunto de 20 mensagens de resposta em um intervalo de aproximadamente 9,4 segundos. O objetivo era avaliar a resposta do serviço sob carga simultânea moderada e identificar eventuais gargalos.

Volume total de requisições  
O arquivo JTL contém 20 linhas de resposta, correspondendo a 20 requisições GET realizadas durante o teste.

Throughput estimado  
O throughput foi calculado dividindo o número total de requisições pelo tempo total do teste em segundos. O tempo total foi determinado pela diferença entre o último e o primeiro timestamp, resultando em 9,422 s. Assim, o throughput médio foi de 20 / 9,422 ≈ 2,12 requisições por segundo.

Latência  
Os valores de latência (coluna Latency) foram analisados para obter os percentis solicitados:  
- p50 (50.º percentile) = 21 ms  
- p90 (90.º percentile) = 28 ms  
- p95 (95.º percentile) = 32 ms  
- p99 (99.º percentile) = 324 ms  

Esses valores indicam que a maior parte das requisições teve latência abaixo de 32 ms, mas houve um pico de 324 ms que domina o 99.º percentile.

Taxa de erros  
Todas as requisições retornaram código 200 e a coluna success é true em cada linha. Portanto, a taxa de erros é 0 % e não há falhas de resposta no conjunto analisado.

Principais gargalos identificados  
1. O primeiro pedido apresentou um tempo de conexão de 309 ms e latência de 324 ms, sugerindo um problema de estabelecimento de conexão ou de resposta do servidor para a primeira requisição em cada sessão.  
2. A presença de um pico de latência isolado (324 ms) indica que, em condições de carga, a aplicação pode experimentar atrasos inesperados possivelmente relacionados a limites de recursos, como pool de conexões, threads ou capacidade de I/O.  
3. O número baixo de requisições por segundo indica que o teste não alcançou a saturação da infraestrutura, o que pode mascarar gargalos que só apareceriam em cargas mais elevadas.

Impacto potencial em ambiente de produção  
Em produção, a ausência de erros mas a existência de latências elevadas pode resultar em uma experiência de usuário insatisfatória, especialmente se as requisições forem parte de fluxos críticos de negócio. Um pico de latência pode aumentar a taxa de timeout de clientes, causar retrys e, consequentemente, aumentar a carga no servidor. Se o volume de tráfego aumentar, esses gargalos poderão se multiplicar, levando a degradação sistêmica.

Recomendações técnicas claras e acionáveis  
1. Ativar e configurar o keep‑alive do protocolo HTTP/1.1 ou HTTP/2 para reduzir o overhead de estabelecimento de conexão; revisar o tempo de timeout de conexão.  
2. Investigar e otimizar o pool de conexões do servidor backend, certificando‑se de que há capacidade suficiente para atender simultaneamente os 20 clientes, especialmente nas primeiras requisições.  
3. Monitorar o tempo de resposta em produção com métricas de latência contínua; configurar alertas quando o 95.º ou 99.º percentile exceder 200 ms.  
4. Executar testes de carga adicionais com maior número de threads (ex.: 100, 500) e com duração mais longa (pelo menos 5 minutos) para identificar pontos de falha que só aparecem quando a carga aumenta.  
5. Analisar logs de aplicação e métricas de sistema (CPU, memória, I/O) para correlacionar picos de latência com eventos de alto consumo de recursos.  
6. Caso o serviço utilize balanceador de carga, confirmar que a distribuição de sessões está balanceada e que não há sobrecarga em instâncias específicas.  
7. Implementar caching de respostas, se aplicável, para reduzir carga no servidor de origem.  
8. Se o serviço for exposto via API Gateway, configurar limitação de taxa (rate limiting) e fallback adequado para proteger a aplicação contra spikes repentinos de tráfego.

Essas ações devem ser priorizadas em conjunto com um plano de monitoramento contínuo para garantir que a aplicação mantenha performance e disponibilidade mesmo em cenários de pico de uso.