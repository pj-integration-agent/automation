Relatório Técnico de Teste de Stress – JMeter

Resumo do cenário de teste
O teste foi conduzido utilizando 2 threads que dispararam requisições do tipo GET ao endpoint https://pokeapi.co/api/v2/pokemon/ditto. Foram gerados 20 amostras em um intervalo de aproximadamente 10 segundos, resultando em um volume total de 20 solicitações. Todas as respostas tiveram código HTTP 200 e foram consideradas bem-sucedidas.

Volume total de requisições
20 requisições foram enviadas durante a execução do teste. O número total de threads no JMeter era 2, o que implica em 10 solicitações por thread em média.

Throughput estimado
O throughput médio calculado a partir do intervalo total de execução (≈9,998 s) foi de 2,0 requisições por segundo. Considerando as duas threads, o throughput médio por thread é de 1,0 req/s. Este valor reflete a taxa de geração de carga em condições de baixa concorrência.

Latência (p50, p90, p95, p99)
A métrica de latência considerada corresponde à coluna “Latency” do arquivo JTL, expressa em milissegundos. Os percentis obtidos foram:

- p50 (mediana) = 36 ms
- p90 = 42 ms
- p95 = 299 ms
- p99 = 715 ms

Os valores de p95 e p99 revelam duas ocorrências de latências anormalmente altas (299 ms e 715 ms), enquanto a maioria das respostas apresenta latências inferiores a 50 ms.

Taxa de erros
Não foram registradas falhas. A taxa de erro é 0 %. Todos os 20 requests retornaram sucesso (responseCode 200).

Principais gargalos identificados
1. Conexão de rede inicial: as primeiras duas requisições apresentaram tempos de conexão de 277 ms e 693 ms, indicando problemas de estabelecimento de conexão (possível resolução de DNS lenta ou handshake TCP demorado).
2. Latências anormais: as ocorrências de 299 ms e 715 ms sugerem que o endpoint remoto (pokeapi.co) pode estar sujeito a variações de carga ou limitações de taxa que geram tempos de resposta maiores quando o tráfego aumenta.
3. Pouca concorrência: com apenas 2 threads, a carga de teste não explorou os limites de escalabilidade do servidor ou da aplicação em teste, limitando a descoberta de gargalos de processamento interno.

Impacto potencial em ambiente de produção
- Se a aplicação em produção for submetida a uma carga maior (ex.: 50 a 100 requisições por segundo), é provável que a latência média aumente, especialmente se o endpoint externo continuar a apresentar variações de tempo de resposta.
- A ausência de Keep‑Alive nas conexões (conectando a cada requisição) aumenta o custo de estabelecimento de conexão, elevando a latência de início de sessão e o consumo de recursos de rede.
- A taxa de erro atual é zero, mas em cenários de carga elevada o endpoint remoto pode impor limites de taxa (rate‑limiting), resultando em respostas 429 ou 503 que não foram capturadas neste teste.

Recomendações técnicas claras e acionáveis
1. Habilitar HTTP Keep‑Alive no JMeter: configure o campo “Use KeepAlive” como “True” para reutilizar conexões TCP e reduzir o tempo de conexão para cada request.
2. Aumentar o número de threads: execute testes com 10, 20 ou 50 threads para avaliar a escalabilidade e identificar quando a latência começa a subir de forma consistente.
3. Implementar um servidor de mock local para o endpoint pokeapi.co: isso elimina variáveis externas e permite controle completo sobre a latência e taxa de erro.
4. Medir DNS: utilize a opção “Use DNS cache” no JMeter e desative a resolução dinâmica de DNS durante o teste para isolar o impacto de resolução de nomes.
5. Analisar o perfil de CPU e memória do servidor de teste: registre métricas de uso de recursos do JMeter e do ambiente de aplicação para verificar se há gargalos internos.
6. Configurar limites de taxa de resposta: se o endpoint externo for controlado pela equipe de produção, negocie limites de taxa adequados ou implemente caching local para reduzir a dependência direta.
7. Documentar e monitorar os tempos de latência em produção: implemente métricas de observabilidade (ex.: Prometheus + Grafana) para detectar desvios em tempo real e correlacioná‑los com eventos de carga.

Conclusão
O teste de stress demonstrou que a aplicação em teste lida bem com baixa carga (20 requisições em 10 s) e mantém zero erros. Entretanto, a presença de duas latências muito altas, a alta latência de conexão nas primeiras requisições e a ausência de Keep‑Alive apontam para possíveis áreas de melhoria. Ao seguir as recomendações acima, será possível aumentar a concorrência, reduzir o tempo de conexão, controlar melhor as respostas externas e garantir que a aplicação mantenha desempenho aceitável mesmo sob carga elevada.